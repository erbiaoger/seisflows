import sys
import numpy as np
import os

from os.path import exists
from obspy.core import Stream, Trace
from obspy import read as obspy_read
from obspy import Stream, Trace, UTCDateTime

# from seisflows.preprocess.plugins import adjoint, misfit
from seisflows.tools import unix
from seisflows.tools.config import Dict, custom_import, get_task_id
# from seisflows.tools.config import import_seisflows
# PAR = sys.modules['seisflows_parameters']
# PATH = sys.modules['seisflows_paths']

# system = sys.modules['seisflows_system']




class Dispersion:
    """seisflows/preprocess/dispersion.py made by Zhiyu Zhang JiLin University in 2023-12-24 13h.
    WD dispersion misfit function's data processing class
    
    from Liu Zhaolun 2DWD code
    """

    def __init__(self, syn_data_format="ascii", obs_data_format="ascii",
                 unit_output="VEL", misfit="waveform", adjoint="waveform", 
                 fmin=None, fmax=None, dx=None, df=None, dk=None, minrec=None, 
                 dfpara=None, dkpara=None, dt=None, nt=None, nx=None,
                 workdir=os.getcwd(), path_preprocess=None,
                 path_solver=None, path_specfem_data=None, path_data=None,
                 path_output=None, channel=None,
                 **kwargs):
        """
        Pyatoa preprocessing parameters

        .. note::
            Paths and parameters listed here are shared with other modules and
            so are not included in the main class docstring.

        :type syn_data_format: str
        :param syn_data_format: data format for reading synthetic traces into
            memory. Shared with solver module. Pyatoa only works with 'ASCII'
            currently.
        :type data_case: str
        :param data_case: How to address 'data' in the workflow, options:
            'data': real data will be provided by the user in
            `path_data/{source_name}` in the same format that the solver will
            produce synthetics (controlled by `solver.format`) OR
            synthetic': 'data' will be generated as synthetic seismograms using
            a target model provided in `path_model_true`. If None, workflow will
            not attempt to generate data.
        :type components: str
        :param components: components to search for synthetic data with. None by
            default which uses a wildcard when searching for synthetics. If
            provided, User only wants to use a subset of components generated by
            SPECFEM. In that case, `components` should be string of letters such
            as 'ZN' (for up and north components)
        :type workdir: str
        :param workdir: working directory in which to look for data and store
            results. Defaults to current working directory
        :type path_solver: str
        :param path_solver: scratch path for all solver related tasks
        :type path_data: str
        :param path_data: path to any externally stored data required by the 
            solver
        """

        self.syn_data_format = syn_data_format.upper()
        self.obs_data_format = obs_data_format.upper()
        self.unit_output = unit_output.upper()
        self.misfit = misfit
        self.adjoint = adjoint
        # self.normalize = normalize

        self.nt = nt
        self.dt = dt
        self.nx = nx
        self.dx = dx
        self.df = df
        self.dk = dk
        self.minrec = minrec
        self.dfpara = dfpara
        self.dkpara = dkpara
        self.fmin = fmin
        self.fmax = fmax
        self.misfit = misfit
        self.adjoint = adjoint
        self.channel = channel

        self.path = Dict(
            scratch=path_preprocess or os.path.join(workdir, "scratch",
                                                    "preprocess"),
            solver=path_solver or os.path.join(workdir, "scratch", "solver"),
            output=path_output or os.path.join(workdir, "output"),
            specfem_data=path_specfem_data,
            data=path_data,
            mainsolver=os.path.join(workdir, "scratch", "solver", "mainsolver"),
            
        )

        self.path["_logs"] = os.path.join(self.path.scratch, "logs")
        self.path["_tmplogs"] = os.path.join(self.path._logs, "tmp")
        self.path["_datasets"] = os.path.join(self.path.scratch, "datasets")
        self.path["_figures"] = os.path.join(self.path.scratch, "figures")

    def check(self):
        """ Checks parameters, paths, and dependencies
        """
        pass
    
    def setup(self):
        """
        Sets up data preprocessing machinery by dynamicalyl loading the
        misfit, adjoint source type, and specifying the expected file type
        for input and output seismic data.
        """
        unix.mkdir(self.path.scratch)


    def quantify_misfit(self, source_name=None, save_residuals=None,
                        export_residuals=None, save_adjsrcs=None, iteration=1,
                        step_count=0, **kwargs):

        fmin = self.fmin
        fmax = self.fmax
        dx = self.dx
        df = self.df
        dk = self.dk
        minrec = self.minrec
        dfpara = self.dfpara
        dkpara = self.dkpara
        path = self.path['mainsolver']

        observed_files, synthetic_files = self._setup_quantify_misfit(source_name)

        obs_data = []
        syn_data = []
        for obs_fid, syn_fid in zip(observed_files, synthetic_files):
            obs = self.read(fid=obs_fid, data_format=self.obs_data_format)
            syn = self.read(fid=syn_fid, data_format=self.syn_data_format)

            for tr_obs, tr_syn in zip(obs, syn):
                # Simple check to make sure zip retains ordering
                # assert(tr_obs.stats.component == tr_syn.stats.component)
                obs_data.append(tr_obs.data)
                syn_data.append(tr_syn.data)
        
        obs_data = np.array(obs_data)
        syn_data = np.array(syn_data)
        
        if self.channel.upper() == "XZ":
            syn_data_X = syn_data[::2, :]
            obs_data_X = obs_data[::2, :]
            syn_data_Z = syn_data[1::2, :]
            obs_data_Z = obs_data[1::2, :]

            if save_residuals:
                dispersion_diff_X = self.calculate_misfit(syn_data_X,obs_data_X,
                                                          fmin,fmax,dx,minrec,dfpara,dkpara)
                dispersion_diff_Z = self.calculate_misfit(syn_data_Z,obs_data_Z,
                                                          fmin,fmax,dx,minrec,dfpara,dkpara)
                np.savetxt(path+'/dispersion_diff_X.txt', dispersion_diff_X)
                np.savetxt(path+'/dispersion_diff_Z.txt', dispersion_diff_Z)

                dispersion_diff_1d=dispersion_diff_X.flatten() + dispersion_diff_Z.flatten()
                np.savetxt(save_residuals, np.abs(dispersion_diff_1d))


                adjsrc_X = self.calculate_adjoint(dispersion_diff_X, syn_data_X,obs_data_X,
                                                  fmin,fmax,dx,minrec,dfpara)
                adjsrc_Z = self.calculate_adjoint(dispersion_diff_Z, syn_data_Z,obs_data_Z,
                                                  fmin,fmax,dx,minrec,dfpara)

                for index, (obs_fid, syn_fid) in enumerate(zip(observed_files, synthetic_files)):
                    obs = self.read(fid=obs_fid, data_format=self.obs_data_format)
                    syn = self.read(fid=syn_fid, data_format=self.syn_data_format)
                    for tr_obs, tr_syn in zip(obs, syn):
                        # Simple check to make sure zip retains ordering
                        # assert(tr_obs.stats.component == tr_syn.stats.component)
                        adj = tr_syn.copy()
                        if tr_obs.stats.channel == "X":
                            adj.data = adjsrc_X[index//2]
                        elif tr_obs.stats.channel == "Z":
                            adj.data = adjsrc_Z[index//2]
                        
                        adj = Stream(adj)
                        fid = os.path.basename(syn_fid)
                        fid = self._rename_as_adjoint_source(fid)
                        self.write(st=adj, fid=os.path.join(save_adjsrcs, fid))

        # Calculate the misfit value and write to file
        elif save_residuals:
            
            dispersion_diff=self.calculate_misfit(syn_data,obs_data,fmin,fmax,dx,minrec,dfpara,dkpara)
            dispersion_diff_1d=dispersion_diff.flatten()
            np.savetxt(save_residuals, dispersion_diff_1d)
            
            adjsrc = self.calculate_adjoint(dispersion_diff, syn_data,obs_data,fmin,fmax,dx,minrec,dfpara)
            
            for index, (obs_fid, syn_fid) in enumerate(zip(observed_files, synthetic_files)):
                obs = self.read(fid=obs_fid, data_format=self.obs_data_format)
                syn = self.read(fid=syn_fid, data_format=self.syn_data_format)
                for tr_obs, tr_syn in zip(obs, syn):
                    # Simple check to make sure zip retains ordering
                    # assert(tr_obs.stats.component == tr_syn.stats.component)
                    adj = tr_syn.copy()
                    
                    adj.data = adjsrc[index//2]
                    adj = Stream(adj)
                    fid = os.path.basename(syn_fid)
                    fid = self._rename_as_adjoint_source(fid)
                    self.write(st=adj, fid=os.path.join(save_adjsrcs, fid))

    # TODO: TypeError: finalize() missing 3 required positional arguments: 'path', 'syn', and 'obs
    def finalize(self):
        """Teardown procedures for the default preprocessing class"""
        pass

    @staticmethod
    def sum_residuals(residuals):
        """
        Returns the summed square of residuals for each event. Following
        Tape et al. 2007

        :type residuals: np.array
        :param residuals: list of residuals from each NTASK event
        :rtype: float
        :return: sum of squares of residuals
        """
        return np.sum(residuals ** 2.)

    def _setup_quantify_misfit(self, source_name):
        """
        Gather waveforms from the Solver scratch directory which will be used
        for generating adjoint sources
        """
        source_name = source_name or self._source_names[get_task_id()]

        obs_path = os.path.join(self.path.solver, source_name, "traces", "obs")
        syn_path = os.path.join(self.path.solver, source_name, "traces", "syn")

        observed = sorted(os.listdir(obs_path))
        synthetic = sorted(os.listdir(syn_path))

        assert(len(observed) != 0 and len(synthetic) != 0), \
            f"cannot quantify misfit, missing observed or synthetic traces"

        # verify observed traces format
        obs_ext = list(set([os.path.splitext(x)[-1] for x in observed]))

        if self.obs_data_format.upper() == "ASCII":
            obs_ext_ok = obs_ext[0].upper() == ".ASCII" or \
                         obs_ext[0].upper() == f".SEM{self.unit_output[0]}"
        else:
            obs_ext_ok = obs_ext[0].upper() == f".{self.obs_data_format}"

        # print(obs_ext, obs_ext_ok)
        # assert(len(obs_ext) == 1 and obs_ext_ok), (
        #     f"observed traces have more than one format or their format "
        #     f"is not the one defined in parameters.yaml"
        # )

        # verify synthetic traces format
        syn_ext = list(set([os.path.splitext(x)[-1] for x in synthetic]))

        if self.syn_data_format == "ASCII":
            syn_ext_ok = syn_ext[0].upper() == ".ASCII" or \
                         syn_ext[0].upper() == f".SEM{self.unit_output[0]}"
        else:
            syn_ext_ok = syn_ext[0].upper() == f".{self.syn_data_format}"

        # assert(len(syn_ext) == 1 and syn_ext_ok), (
        #     f"synthetic traces have more than one format or their format "
        #     f"is not the one defined in parameters.yaml"
        # )

        # remove data format
        observed = [os.path.splitext(x)[0] for x in observed]
        synthetic = [os.path.splitext(x)[0] for x in synthetic]

        # only return traces that have both observed and synthetic files
        matching_traces = sorted(list(set(synthetic).intersection(observed)))

        assert(len(matching_traces) != 0), (
            f"there are no traces with both observed and synthetic files for "
            f"source: {source_name}; verify that observations and synthetics "
            f"have the same name including channel code"
        )

        observed.clear()
        synthetic.clear()

        for file_name in matching_traces:
            observed.append(os.path.join(obs_path, f"{file_name}{obs_ext[0]}"))
            synthetic.append(os.path.join(syn_path, f"{file_name}{syn_ext[0]}"))

        assert(len(observed) == len(synthetic)), (
            f"number of observed traces does not match length of synthetic for "
            f"source: {source_name}"
        )

        return observed, synthetic

    def calculate_adjoint(self, dispersion_diff, syn, obs, fmin, fmax, dx, minrec, dfpara):
        # 函数定义，接收多个参数，包括合成（模拟）数据、观测数据、频率范围、空间间隔、最小记录数和频率参数。

        nt, dt, nx = self.nt, self.dt, self.nx
        # 获取时间步数(nt)，时间间隔(dt)和空间节点数(nx)。

        path = self.path['mainsolver']
        # 获取主求解器的路径。

        df = 1./(nt*dt)
        # 计算频率间隔(df)。

        ntextend = nt
        if dfpara < df:
            df = dfpara
            ntextend = int(round(1/df/dt))
        # 如果输入的频率参数(dfpara)小于计算出的频率间隔，则重新计算频率间隔和扩展后的时间步数(ntextend)。

        nfmin = int(round(fmin/df))
        nfmax = int(round(fmax/df))
        nfcount = nfmax - nfmin + 1
        # 计算最小和最大频率在频率数组中的索引，以及它们之间的频率数目。

        # dispersion_diff = self.dispersion_diff
        # 获取频散差分。

        syn_ft = np.fft.rfft(syn, ntextend)
        # 对合成数据进行实数快速傅里叶变换。

        syn_ft_adj = np.zeros(syn_ft.shape, np.complex128)
        # 初始化伴随（逆）傅里叶变换数组。

        sourceid = self.sourceid 
        dist = self.dist 
        num_rec_left = sourceid 
        num_rec_right = nx - sourceid
        # 获取源位置、距离分布以及左右接收器数量。

        scal = 0.1
        Areal = np.zeros(nfcount)
        # 初始化缩放因子和实部数组。

        if num_rec_left >= minrec:
            # 如果左侧接收器数量大于等于最小记录数。
            for iff in range(nfcount):
                A = 0.
                for ix in range(sourceid):
                    A = A - 2 * np.pi * dist[ix]**2 * syn_ft[ix][iff + nfmin] * np.conjugate(syn_ft[ix][iff + nfmin])
                Areal[iff] = np.real(A)
            factor = scal * max(abs(Areal))
            for iff in range(nfcount):
                if abs(Areal[iff]) >= 0:
                    for ix in range(sourceid):
                        syn_ft_adj[ix][iff + nfmin] = (1j * dispersion_diff[1][iff] * dist[ix]) * syn_ft[ix][iff + nfmin] / (Areal[iff] - factor)
            # 对左侧接收器进行伴随场的计算。

        if num_rec_right >= minrec:
            # 如果右侧接收器数量大于等于最小记录数。
            for iff in range(nfcount):
                A = 0.
                for ix in range(sourceid, nx):
                    A = A - 2 * np.pi * dist[ix]**2 * syn_ft[ix][iff + nfmin] * np.conjugate(syn_ft[ix][iff + nfmin])
                Areal[iff] = np.real(A)
            factor = scal * max(abs(Areal))
            for iff in range(nfcount):
                if abs(Areal[iff]) >= 0:
                    for ix in range(sourceid, nx):
                        syn_ft_adj[ix][iff + nfmin] = (1j * dispersion_diff[0][iff] * dist[ix]) * syn_ft[ix][iff + nfmin] / (Areal[iff] - factor)
            # 对右侧接收器进行伴随场的计算。

        adj_temp = np.fft.irfft(syn_ft_adj)
        # 对伴随场进行逆傅里叶变换。

        adj = obs
        for ii in range(nx):
            adj[ii].data = adj_temp[ii][0:nt]
        # 将逆变换结果存储回观测数据结构中。
        

        return adj
        # 返回调整后的观测数据作为伴随场。

    def calculate_misfit(self,syn,obs,fmin,fmax,dx,minrec,dfpara,dkpara):
        nt, dt, nx = self.nt, self.dt, self.nx
        path = self.path['mainsolver']
        df = 1./(nt*dt)
        ntextend = nt
        if dfpara<df:
            df=dfpara
            ntextend = int(round(1/df/dt))
        nfmin=int(round(fmin/df))
        nfmax=int(round(fmax/df))
        nfcount=nfmax-nfmin+1                   # number of frequency points
        self.nfcount=nfcount
        dispersion_diff=np.zeros((2,nfcount))

        syn_ft=np.fft.rfft(syn,ntextend)        # 一维傅立叶变换，(nx, nt//2+1)
        obs_ft=np.fft.rfft(obs,ntextend)
        sourceid,dist,angl = self.get_source_ID_and_SR_distance(path,nx)
        self.sourceid = sourceid
        self.dist = dist
        num_rec_left = sourceid 
        num_rec_right = nx-sourceid
        if num_rec_left >= minrec:
            dk = 1./(num_rec_left*dx)
            nxextend = num_rec_left
            if dkpara<dk:
                dk=dkpara
                nxextend = int(round(1/dk/dx))
            for iff in range(0,nfcount):
                syn_ft_fx = np.fft.fft(syn_ft[sourceid-1::-1,iff+nfmin],nxextend)
                obs_ft_fx = np.fft.fft(obs_ft[sourceid-1::-1,iff+nfmin],nxextend)
                phicon=np.real(np.correlate(obs_ft_fx,syn_ft_fx,"full"))
                #phicon = (np.correlate(abs(obs_ft_fx),abs(syn_ft_fx),"full"))
                #phicon=np.imag(np.correlate(obs_ft_fx,syn_ft_fx,"full"))
                dispersion_diff[1][iff] = (np.argmax(phicon)-nxextend+1)*dk
        if num_rec_right >= minrec:
            dk = 1./(num_rec_right*dx)
            nxextend = num_rec_right
            if dkpara<dk:
                dk=dkpara
                nxextend = int(round(1/dk/dx))
            for iff in range(0,nfcount):
                syn_ft_fx = np.fft.fft(syn_ft[sourceid:nx,iff+nfmin],nxextend)
                obs_ft_fx = np.fft.fft(obs_ft[sourceid:nx,iff+nfmin],nxextend)
                phicon=np.real(np.correlate(obs_ft_fx,syn_ft_fx,"full"))
                #phicon = (np.correlate(abs(obs_ft_fx),abs(syn_ft_fx),"full"))
                #phicon=np.imag(np.correlate(obs_ft_fx,syn_ft_fx,"full"))
                dispersion_diff[0][iff] = (np.argmax(phicon)-nxextend+1)*dk


        return dispersion_diff

    def get_source_ID_and_SR_distance(self,path,nx):
        sx,sz=self.get_source_coords_new(path)
        rx,rz=self.get_receiver_coords_new(path,nx)
        dist = np.zeros(nx)
        angl = np.zeros(nx)
        for ix in range(0,nx):
            dist[ix]=np.sqrt((rx[ix]-sx)**2+(rz[ix]-sz)**2)
            angl[ix]=np.arctan2(rz[ix]-sz,rx[ix]-sx)
            

        return np.argmin(abs(dist)), dist, angl

    def get_receiver_coords_new(self,path,nx):
        #Read STATIONS file from path+'DATA/STATIONS'
        stations = np.genfromtxt(path+'/DATA/STATIONS',dtype=None)
        ntemp = stations.shape
        assert ntemp[0]==nx
        rx=np.zeros(nx)
        rz=np.zeros(nx)
        for ix in range(nx):
            rx[ix] = stations[ix][2]
            rz[ix] = stations[ix][3]

        return rx,rz

    def get_source_coords_new(self, path):
        with open(path+'/DATA/SOURCE','r') as f:
            for line in f.readlines():
                tmp0=line.strip().split('\n')
                tmp1=tmp0[0].split('=')
                tmp2=tmp1[0].split()
                print(tmp2)
                empty=[]
                if tmp2 == empty:
                    continue
                else:
                    if tmp2[0]=='xs':
                        print('xs')
                        sx=(float(tmp1[1].split()[0]))
                        print(sx)
                    if tmp2[0]=='zs':
                        sz=(float(tmp1[1].split()[0]))
                    
            return sx,sz

    def get_dist(self,rx,rz,rx1,rz1):
        return(np.sqrt((rx-rx1)**2+(rz-rz1)**2))



    def read(self, fid, data_format):
        """
        Waveform reading functionality. Imports waveforms as Obspy streams

        :type fid: str
        :param fid: path to file to read data from
        :type data_format: str
        :param data_format: format of the file to read data from
        :rtype: obspy.core.stream.Stream
        :return: ObsPy stream containing data stored in `fid`
        """
        st = None
        if data_format.upper() == "SU":
            st = obspy_read(fid, format="SU", byteorder="<")
        elif data_format.upper() == "SAC":
            st = obspy_read(fid, format="SAC")
        elif data_format.upper() == "ASCII":
            st = read_ascii(fid)
        return st

    def write(self, st, fid):
        """
        Waveform writing functionality. Writes waveforms back to format that
        SPECFEM recognizes

        :type st: obspy.core.stream.Stream
        :param st: stream to write
        :type fid: str
        :param fid: path to file to write stream to
        """
        if self.syn_data_format.upper() == "SU":
            for tr in st:
                # Work around for ObsPy data type conversion
                tr.data = tr.data.astype(np.float32)
            max_delta = 0.065535
            dummy_delta = max_delta

            if st[0].stats.delta > max_delta:
                for tr in st:
                    tr.stats.delta = dummy_delta

            # Write data to file
            st.write(fid, format="SU")

        elif self.syn_data_format.upper() == "ASCII":
            for tr in st:
                # Float provides time difference between starttime and default
                time_offset = float(tr.stats.starttime)
                data_out = np.vstack((tr.times() + time_offset, tr.data)).T
                np.savetxt(fid, data_out, ["%13.7f", "%17.7f"])

    def _rename_as_adjoint_source(self, fid):
        """
        Rename synthetic waveforms into filenames consistent with how SPECFEM
        expects adjoint sources to be named. Usually this just means adding
        a '.adj' to the end of the filename
        """
        if not fid.endswith(".adj"):
            if self.syn_data_format.upper() == "SU":
                fid = f"{fid}.adj"
            elif self.syn_data_format.upper() == "ASCII":
                # Differentiate between SPECFEM3D and 3D_GLOBE
                # SPECFEM3D: NN.SSSS.CCC.sem?
                # SPECFEM3D_GLOBE: NN.SSSS.CCC.sem.ascii
                ext = os.path.splitext(fid)[-1]  
                # SPECFEM3D
                if ".sem" in ext:
                    fid = fid.replace(ext, ".adj")
                # GLOBE (!!! Hardcoded to only work with ASCII format)
                elif ext == ".ascii":
                    root, ext1 = os.path.splitext(fid)  # .ascii
                    root, ext2 = os.path.splitext(root)  # .sem
                    fid = fid.replace(f"{ext2}{ext1}", ".adj")

        return fid
    
    def initialize_adjoint_traces(self, data_filenames, output,
                                  data_format=None):
        """
        SPECFEM requires that adjoint traces be present for every matching
        synthetic seismogram. If an adjoint source does not exist, it is
        simply set as zeros. This function creates all adjoint traces as
        zeros, to be filled out later

        Appends '.adj. to the solver filenames as expected by SPECFEM (if they
        don't already have that extension)

        TODO there are some sem2d and 3d specific tasks that are not carried
        TODO over here, were they required?

        :type data_filenames: list of str
        :param data_filenames: existing solver waveforms (synthetic) to read.
            These will be copied, zerod out, and saved to path `save`. Should
            come from solver.data_filenames
        :type output: str
        :param output: path to save the new adjoint traces to.
        """
        for fid in data_filenames:
            st = self.read(fid=fid, data_format=self.syn_data_format).copy()
            fid = os.path.basename(fid)  # drop any path before filename
            for tr in st:
                tr.data *= 0

            adj_fid = self._rename_as_adjoint_source(fid)

            # Write traces back to the adjoint trace directory
            self.write(st=st, fid=os.path.join(output, adj_fid))




def read_ascii(fid, origintime=None):
    """
    Read waveforms in two-column ASCII format. This is copied directly from
    pyatoa.utils.read.read_sem()
    """
    try:
        times = np.loadtxt(fname=fid, usecols=0)
        data = np.loadtxt(fname=fid, usecols=1)

    # At some point in 2018, the Specfem developers changed how the ascii files
    # were formatted from two columns to comma separated values, and repeat
    # values represented as 2*value_float where value_float represents the data
    # value as a float
    except ValueError:
        times, data = [], []
        with open(fid, 'r') as f:
            lines = f.readlines()
        for line in lines:
            try:
                time_, data_ = line.strip().split(',')
            except ValueError:
                if "*" in line:
                    time_ = data_ = line.split('*')[-1]
                else:
                    raise ValueError
            times.append(float(time_))
            data.append(float(data_))

        times = np.array(times)
        data = np.array(data)

    if origintime is None:
        origintime = UTCDateTime("1970-01-01T00:00:00")

    # We assume that dt is constant after 'precision' decimal points
    delta = round(times[1] - times[0], 4)

    # Honor that Specfem doesn't start exactly on 0
    origintime += times[0]

    # Write out the header information. Deal with the fact that SPECFEM2D/3D and
    # 3D_GLOBE have slightly different formats for their filenames
    net, sta, cha, *fmt = os.path.basename(fid).split('.')
    stats = {"network": net, "station": sta, "location": "",
             "channel": cha, "starttime": origintime, "npts": len(data),
             "delta": delta, "mseed": {"dataquality": 'D'},
             "time_offset": times[0], "format": fmt[0]
             }
    st = Stream([Trace(data=data, header=stats)])

    return st